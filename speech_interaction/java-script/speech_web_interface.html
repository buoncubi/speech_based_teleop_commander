<!DOCTYPE html>
<!-- speech-to-text pawered by google web API -->
<!-- text-to-speech pawered by http://responsivevoice.org/-->

<meta charset="utf-8">
<!-- text-to-speech library -->
<script src='https://code.responsivevoice.org/responsivevoice.js'></script> 
<!-- ros interfacing library -->
<script type="text/javascript" src="http://static.robotwebtools.org/EventEmitter2/current/eventemitter2.min.js"></script>
<script type="text/javascript" src="http://static.robotwebtools.org/roslibjs/current/roslib.min.js"></script>

<!-- [[[[[[[[[[[[[[[[[[[[[[[[  VISUAL OBJECTS  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<title>Google Speech Recogniton and Synthesizer Demo Interface for ROS</title>
<style>
	* {
		font-family: Verdana, Arial, sans-serif;
	}
	a:link {
		color:#009933;
	}
	a:visited {
		color:#006600;
	}
	a:hover {
		color:#00cc99;
	}
	.center {
		padding: 10px;
		text-align: center;
	}
	.final {
		color: black;
		padding-right: 3px; 
	}
	.interim {
		color: gray;
	}
	.info {
		font-size: 14px;
		text-align: center;
		color: #777;
		display: none;
	}
	.right {
		float: right;
	}
	.sidebyside {
		display: inline-block;
		width: 45%;
		min-height: 40px;
		text-align: left;
		vertical-align: top;
	}
	#headline {
		font-size: 40px;
		font-weight: 300;
	}
	#info {
		font-size: 20px;
		text-align: center;
		color: #777;
		visibility: hidden;
	}
	#infoSpeech{
		font-size: 20px;
		text-align: center;
		color: #777;
	}
	#info_priority{
		font-size: 14px;
		text-align: center;
		color: #777;
	}
	#results {
		font-size: 14px;
		font-weight: bold;
		border: 1px solid #ddd;
		padding: 15px;
		text-align: left;
		min-height: 80px;
	}
	#inter_results {
		font-size: 12px;
		border: 1px solid #ddd;
		padding: 15px;
		text-align: left;
		min-height: 50px;
	}
	#resultsSpeech{ 
		font-size: 12px;
		border: 1px solid #ddd;
		padding: 15px;
		text-align: left;
		min-height: 50px;
	}
	#start_button {
		border: 0;
		background-color:transparent;
		padding: 0;
	}
	#section{
		font-size: 16px;
		font-weight: bold;
		color: #777;
		text-align: right;
	}
	#documentation{
		font-size: 12px;
		color: #777;
		text-align: left;
	}
</style>


<!-- [[[[[[[[[[[[[[[[[[[[[[[[   SET PAGE CONTENTS  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<!-- title -->
<h1 class="center" id="headline">
	Google Speech Recogniton <a href="https://developers.google.com/web/updates/2013/01/Voice-Driven-Web-Apps-Introduction-to-the-Web-Speech-API?hl=en"> API</a> and  <a href="http://responsivevoice.org/"> Synthesizer</a>. <br> A demo Interface for <a href="http://wiki.ros.org/roslibjs">ROSbridge</a>. </h1>


<!-- informations on how to use the system -->
<hr>  
<div id="section">
	Information.
</div>

<div class="left" id="documentation">
<p> 
This web interface implements a speech-text Recognition and Synthesizer interface to Robotic Operating System (tested with Indigo version).<br>
Particularly, it allow a user to continuously speak (after the microphone button is pressed) in order to publish the recognised text to the <code style="background-color:#e1eaea">/speech_to_text</code> ROS topic. As an example the node <code style="background-color:#e1eaea">speech_example</code> of the package <code style="background-color:#e1eaea">speech_interaction</code> modifies the string and talk back to the user.<br>
In order to use it you must to connect to ROS bridge by calling: <code style="background-color:#e1eaea">roslaunch rosbridge_server rosbridge_websocket.launch</code> and run the node with: <code style="background-color:#e1eaea">rosrun speech_interaction speech_example</code>. <br>
Also, take in mind that this page works only on Chrome or Chromium. Moreover, if this html page is launched from local file you have to open the Browser in not safe mode (otherwise the microphone is disabled) by typing in a terminal: <code style="background-color:#e1eaea">usr/bin/chromium-browser --user-data-dir=”/var/tmp/Chrome” --disable-web-security</code><br>
Please, see also the java console <code style="background-color:#e1eaea">alt+shift+I</code> as well the complete ROSlaunch configurations as: <code style="background-color:#e1eaea">roslaunch speech_interaction speech_back_example.launch</code>.<br>
Moreover, consider that there is a Robot or Human speaker priority (given by ROS parameters). Particularly, if the agent with the priority speecks the other cannot speak. If the priority is given to the Human, the robot will consider olways the most up to date sentence given by the Human.
</p>
<p>
The tools used in this scripts are powered by: Google for <a href="https://dvcs.w3.org/hg/speech-api/raw-file/tip/speechapi.html">Speech-To-Text API</a>,
ResponsiveVoice.JS for <a href="http://responsivevoice.org/">Text-to-Speech API</a> mand <a href="http://wiki.ros.org/rosbridge_suite/Tutorials/RunningRosbridge">ROSjs</a> for bridging javascripts with ROS middleware.
</p>
</div>

<!-- sppech-to-text section -->
<hr>  
<div id="section">
	Speech-to-Text.
</div>
<div id="info">
	<p id="info_start">Click on the microphone icon and begin speaking.<br><br></p>
	<p id="info_speak_now">Speak now.<br><br></p>
	<p id="info_no_speech">No speech was detected. You may need to adjust your <a href="//support.google.com/chrome/bin/answer.py?hl=en&amp;answer=1407892"> microphone settings</a>.<br><br></p>
	<p id="info_no_microphone" style="display:none"> No microphone was found. Ensure that a microphone is installed and that <a href="//support.google.com/chrome/bin/answer.py?hl=en&amp;answer=1407892"> microphone settings</a> are configured correctly.<br><br></p>
	<p id="info_allow">Click the "Allow" button above to enable your microphone.</p>
	<p id="info_denied">Permission to use microphone was denied. <br><br></p>
	<p id="info_blocked">Permission to use microphone is blocked. To change, go to chrome://settings/content/microphone <br><br></p>
	<p id="info_upgrade">Web Speech API is not supported by this browser. Upgrade to <a href="//www.google.com/chrome">Chrome</a> version 25 or later. <br><br></p>
	<p id="info_pub">command send to ROS topic /speech_to_text!<br>You can keep speaking...<br><br></p> 
	<p id="info_robot_priority">The speaker priority is given to the Robot. You cannot speeach while it is speaking.</p>
</div>
<div class="right">
	<button id="start_button" onclick="startButton(event)">
	<img id="start_img" src="mic-resources/mic.gif" alt="Start"></button>
</div>
<div id="inter_results">
	Intermidiate recognised string from speech:<br>
	<span id="interim_span" class="interim"></span>
	<p>
</div>
<div id="results">
	Final recognised string from speech:<br>
	<span id="final_span" class="final"></span>
	<p>
</div>
<div class="left" id="div_language">
	<br>Select the speaking language: &nbsp
	<select id="select_language" onchange="updateCountry()"></select>
	&nbsp;&nbsp; 
	<select id="select_dialect"></select>
</div>
<br>


<!-- text-to-speech section -->
<hr>  
<div id="section">
	Text-To-Speech.
</div>
<div id="infoSpeech">
	<p id="infoSpeech_start">Speak and listen here what the system would said to you.<br><br></p>
	<p id="infoSpeech_error">Your brosware does not support audio speaking or an synthetiser error occurs!<br><br></p>
	<p id="infoSpeech_noRobot">No robot connected<br><br></p>
	<p id="infoSpeech_speak">Robot is speaking...<br><br></p>
	<p id="info_human_priority">The speaker priority is given to the Human. The robot will stop speaking as soon as you speak.</p>
</div>
<div id="resultsSpeech">
	Final string for the Speaker:<br>
	<span id="final_return" class="final"></span>
	<p>
</div>

<hr>  
<div id="section">
	ROS state.
</div>
<div class="center" id="statusIndicator">
	<p id="connecting" style="color:#FFBF00; display:none"> <br> Connecting to ROSbridge ... </p>
    <p id="connected" style="color:#009933; display:none"> <br> Successfully connected to ROSbridge :) </p>
    <p id="error" style="color:#FF4800; display:none"> <br> !!! Error in the backend !!! </p>
    <p id="closed" style="color:#BA2D1E; display:none"> <br> ??? Connection to ROSbridge closed ??? <br> Try to run: <code>roslaunch rosbridge_server rosbridge_websocket.launch</code> </p>
</div>
<div class="left">
	<br>Select the <code style="background-color:#e1eaea">agent_priority</code>:
	<select id="priority_chooser" onchange="priorityUpdate(this.value);">
		<option value="human_priority_set" selected="selected">Human Speaker Priority</option>
		<option value="robot_priority_set">Robot Speaker Priority</option>
	</select>
    (this parameter is synchronised with ROS !!!)
    <br><br>
</div>
<div id="info_priority" class="left">
    <p id="humanPriority">The human has the interaction priority. The robot is always focusing on your last query. You can do other querings while it is providing an answer.</p>
	<p id="robotPriority">The robot has the interaction priority. You cannot speech when the rebot is providing an answer.</p>
	<p id="errorPriority">Error on setting the priority from ROS parameters, you can specify only: <code style="background-color:#e1eaea">human</code> or <code style="background-color:#e1eaea">robot</code>. Using the default value: Human-Priority</p>
</div>



<!-- [[[[[[[[[[[[[[[[[[[[[[[[   JAVA SCRIPT FOR SPEECH-TO-TEXT  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<script>
	var langs =
	[['Afrikaans',			['af-ZA']],
	['Bahasa Indonesia',	['id-ID']],
	['Bahasa Melayu',		['ms-MY']],
	['Català',				['ca-ES']],
	['Čeština',				['cs-CZ']],
	['Deutsch',				['de-DE']],
	['English',				['en-AU', 'Australia'],
							['en-CA', 'Canada'],
							['en-IN', 'India'],
							['en-NZ', 'New Zealand'],
							['en-ZA', 'South Africa'],
							['en-GB', 'United Kingdom'],
							['en-US', 'United States']],
	['Español',				['es-AR', 'Argentina'],
							['es-BO', 'Bolivia'],
							['es-CL', 'Chile'],
							['es-CO', 'Colombia'],
							['es-CR', 'Costa Rica'],
							['es-EC', 'Ecuador'],
							['es-SV', 'El Salvador'],
							['es-ES', 'España'],
							['es-US', 'Estados Unidos'],
							['es-GT', 'Guatemala'],
							['es-HN', 'Honduras'],
							['es-MX', 'México'],
							['es-NI', 'Nicaragua'],
							['es-PA', 'Panamá'],
							['es-PY', 'Paraguay'],
							['es-PE', 'Perú'],
							['es-PR', 'Puerto Rico'],
							['es-DO', 'República Dominicana'],
							['es-UY', 'Uruguay'],
							['es-VE', 'Venezuela']],
	['Euskara',				['eu-ES']],
	['Français',			['fr-FR']],
	['Galego',				['gl-ES']],
	['Hrvatski',			['hr_HR']],
	['IsiZulu',				['zu-ZA']],
	['Íslenska',			['is-IS']],
	['Italiano',			['it-IT', 'Italia'],
							['it-CH', 'Svizzera']],
	['Magyar',				['hu-HU']],
	['Nederlands',			['nl-NL']],
	['Norsk bokmål',		['nb-NO']],
	['Polski',				['pl-PL']],
	['Português',			['pt-BR', 'Brasil'],
							['pt-PT', 'Portugal']],
	['Română',				['ro-RO']],
	['Slovenčina',			['sk-SK']],
	['Suomi',				['fi-FI']],
	['Svenska',				['sv-SE']],
	['Türkçe',				['tr-TR']],
	['български',			['bg-BG']],
	['Pусский',				['ru-RU']],
	['Српски',				['sr-RS']],
	['한국어',				['ko-KR']],
	['中文',					['cmn-Hans-CN', '普通话 (中国大陆)'],
							['cmn-Hans-HK', '普通话 (香港)'],
							['cmn-Hant-TW', '中文 (台灣)'],
							['yue-Hant-HK', '粵語 (香港)']],
	['日本語',				['ja-JP']],
	['Lingua latīna',		['la']]];

	var humanPriority = true; // if false means robot priority // true is the default value but it can set form ROS arguments (see ros launch)
	var humanIsSpeaking = false;
	var robotIsSpeaking = false;

	for (var i = 0; i < langs.length; i++) {
		select_language.options[i] = new Option(langs[i][0], i);
	}
	select_language.selectedIndex = 6;
	updateCountry();
	select_dialect.selectedIndex = 6;
	showInfo('info_start');
	showInfoSpeaking('infoSpeech_start');

	function updateCountry() {
		for (var i = select_dialect.options.length - 1; i >= 0; i--) {
			select_dialect.remove(i);
		}
		var list = langs[select_language.selectedIndex];
		for (var i = 1; i < list.length; i++) {
			select_dialect.options.add(new Option(list[i][1], list[i][0]));
		}
		select_dialect.style.visibility = list[1].length == 1 ? 'hidden' : 'visible';
	}

	var final_transcript = '';
	var final_confidence = 0.0;
	var recognizing = false;
	var ignore_onend;
	var start_timestamp;
	if (!('webkitSpeechRecognition' in window)) {
		upgrade();
	} else {
		start_button.style.display = 'inline-block';
		var recognition = new webkitSpeechRecognition();
		recognition.continuous = true;
		recognition.interimResults = true;

		recognition.onstart = function() {
			recognizing = true;
			showInfo('info_speak_now');
			start_img.src = 'mic-resources/mic-animate.gif';			
		};

		recognition.onerror = function(event) {
			if (event.error == 'no-speech') {
				start_img.src = 'mic-resources/mic.gif';
				showInfo('info_no_speech');
				ignore_onend = true;
			}
			if (event.error == 'audio-capture') {
				start_img.src = 'mic-resources/mic.gif';
				showInfo('info_no_microphone');
				ignore_onend = true;
			}
			if (event.error == 'not-allowed') {
				if (event.timeStamp - start_timestamp < 100) {
					showInfo('info_blocked');
				} else {
					showInfo('info_denied');
				}
				ignore_onend = true;
			}
		};

		recognition.onend = function() {
			recognizing = false;
			if (ignore_onend) {
				return;
			}
			start_img.src = 'mic-resources/mic.gif';
			if (!final_transcript) {
				showInfo('info_start');
				return;
			}
			showInfo('');
			if (window.getSelection) {
				window.getSelection().removeAllRanges();
				var range = document.createRange();
				range.selectNode(document.getElementById('final_span'));
				window.getSelection().addRange(range);
			}
		};

		recognition.onresult = function(event) {
		
		    
	        var colorComputing = new ROSLIB.Param({
		        ros : ros,
		        name : '/color_key'
	        });
			colorComputing.set(4)
		
		
			var interim_transcript = '';
			var transcript_final_log = '';
			var transcript_interim_log = '';
			var interim_confidence = 0.0;
			var final_result = true;

			var humanCanSpeack = true;
			if( robotIsSpeaking && humanIsSpeaking){
				if( ! humanPriority){
					humanCanSpeack = false;
				}
			}
			if( humanCanSpeack){
				// get transcript and confidence results (search for best condifence !! ??)
				for (var i = event.resultIndex; i < event.results.length; ++i) {
					if (event.results[i].isFinal) {
						if( event.results[i][0].confidence > final_confidence){
							final_transcript += event.results[i][0].transcript;
							final_confidence = event.results[i][0].confidence;
						}
					} else {
						if( event.results[i][0].confidence > interim_confidence){
							interim_transcript += event.results[i][0].transcript;
							interim_confidence = event.results[i][0].confidence;
						}
						final_result = false;
					}
				}
				// print the results on the console
				if ( final_result){
					transcript_final_log = '[' + final_confidence + ']\t' + final_transcript;	 
					humanIsSpeaking = false;
				} else {
					transcript_interim_log = '[' + interim_confidence + ']\t'  + interim_transcript;
					humanIsSpeaking = true;
				}  
				transcript_final_log = capitalize( transcript_final_log);   
				final_span.innerHTML = linebreak( transcript_final_log);
				interim_span.innerHTML = linebreak( transcript_interim_log);
				if ( final_result){ //(final_transcript || interim_transcript) {
					showInfo( "info_pub");
					// publish data on ROS
					var message = new ROSLIB.Message({
						language : recognition.lang,
						transcript : final_transcript,
						confidence : final_confidence
					});
					pub.publish( message);					
					// clear recognised sentence 	
					final_transcript = ''; 
					final_confidence = 0.0;
				}
			} else {
				interim_transcript = '';
				interim_confidence = 0.0;
				interim_span.innerHTML = linebreak( '');
				showInfo( 'info_robot_priority');
			}
		};
	}

	function upgrade() {
		start_button.style.visibility = 'hidden';
		showInfo('info_upgrade');
	}

	var two_line = /\n\n/g;
	var one_line = /\n/g;
	function linebreak(s) {
		return s.replace(two_line, '<p></p>').replace(one_line, '<br>');
	}

	var first_char = /\S/;
	function capitalize(s) {
		return s.replace(first_char, function(m) { return m.toUpperCase(); });
	}


	function startButton(event) {
		if (recognizing) {
			recognition.stop();
			return;
		}
		final_transcript = '';
		//recognition.lang = select_dialect.value;
		recognition.start();
		ignore_onend = false;
		final_span.innerHTML = '';
		interim_span.innerHTML = '';
		start_img.src = 'mic-resources/mic-slash.gif';
		showInfo('info_allow');
		start_timestamp = event.timeStamp;
	}

	function showInfo(s) {
		if (s) {
			for (var child = info.firstChild; child; child = child.nextSibling) {
				if (child.style) {
					child.style.display = child.id == s ? 'inline' : 'none';
				}
			}
			info.style.visibility = 'visible';
		} else {
			info.style.visibility = 'hidden';
		}
	}

	function showInfoSpeaking(s) {
		if (s) {
			for (var child = infoSpeech.firstChild; child; child = child.nextSibling) {
				if (child.style) {
					child.style.display = child.id == s ? 'inline' : 'none';
				}
			}
			info.style.visibility = 'visible';
		} else {
			info.style.visibility = 'hidden';
		}
	}

	function showInfoPriority(s) {
		if (s) {
			for (var child = info_priority.firstChild; child; child = child.nextSibling) {
				if (child.style) {
					child.style.display = child.id == s ? 'inline' : 'none';
				}
			}
			info.style.visibility = 'visible';
		} else {
			info.style.visibility = 'hidden';
		}
	}

	function priorityUpdate(s) {
		if ( s == 'human_priority_set'){
			humanPriority = true;
			showInfoPriority( 'humanPriority');
		}else{
			humanPriority = false;
			showInfoPriority( 'robotPriority');
		}        
		// Setting a param value to ROS
		agent_priority.set( humanPriority);
	}
</script>



<!-- [[[[[[[[[[[[[[[[[[[[[[[[  JAVA SCRIPT FOR ROS_BRIDGE & TEXT-TO-SPEECh  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<script>
	// Connecting to ROS
	var ros = new ROSLIB.Ros();

	// manage states and errors
	// If there is an error on the backend, an 'error' emit will be emitted.
	ros.on('error', function(error) {
		showInfoSpeaking('infoSpeech_noRobot'); 
		document.getElementById('connecting').style.display = 'none';
		document.getElementById('connected').style.display = 'none';
		document.getElementById('closed').style.display = 'none';
		document.getElementById('error').style.display = 'inline';
	});
	// Find out exactly when we made a connection.
	ros.on('connection', function() {
		console.log('Connection made!');
		document.getElementById('connecting').style.display = 'none';
		document.getElementById('error').style.display = 'none';
		document.getElementById('closed').style.display = 'none';
		document.getElementById('connected').style.display = 'inline';
	});
	ros.on('close', function() {
		console.log('Connection closed.');
		document.getElementById('connecting').style.display = 'none';
		document.getElementById('connected').style.display = 'none';
		document.getElementById('closed').style.display = 'inline';
	});

	// Create a connection to the rosbridge WebSocket server.
	ros.connect('ws://localhost:9090');


	// create a publisher 
	var pub = new ROSLIB.Topic({
		ros : ros,
		name : '/speech_to_text',
		messageType : 'speech_interaction/Speech2text'
	});

	//Subscribing to a Topic
	var listener = new ROSLIB.Topic({
		ros : ros,
		name : '/text_to_speech',
		messageType : 'speech_interaction/Text2speech'
	});

	// Then we add a callback to be called every time a message is published on this topic.
	listener.subscribe( function(message) {
		// manage speaker priority
		var robotCanSpeack = true;
		if( robotIsSpeaking && humanIsSpeaking){
			if( humanPriority){
				robotCanSpeack = false;
			}
		}
		if( robotCanSpeack){
			if(responsiveVoice.voiceSupport()) {
				// visualise speeck
				final_return.innerHTML = linebreak( message.text + '\n[language: ' + message.language + '] [ volume: ' + message.volume + '] [ pitch: ' + message.pitch + '] [ rate: ' + message.rate + ']');
				// speech
				showInfoSpeaking('infoSpeech_speak');
				responsiveVoice.speak( message.text, message.language, callbacks, message.volume, message.pitch, message.rate);	
			} else {
				showInfoSpeaking('infoSpeech_error'); 
			}
		} else {
			showInfoSpeaking( 'info_human_priority');
		}
	});

	// functions to manage text to speech 
	var callbacks = {
		onstart: voiceStartCallback,
		onend: voiceEndCallback,
		onerror: voiceErrorCallback, 
		onpause: voicePauseCallback
		// onresume
	}
	function voiceStartCallback() {
		robotIsSpeaking = true;
	}
	function voiceEndCallback() {
		showInfoSpeaking('infoSpeech_start');
		if( !humanPriority)
			showInfo( 'info_speak_now');
		robotIsSpeaking = false;
	}
	function voiceErrorCallback() {
		showInfoSpeaking('infoSpeech_error'); 
		robotIsSpeaking = false;
	}
	function voicePauseCallback() {
		showInfoSpeaking( 'info_human_priority');
		robotIsSpeaking = false;
	}

  	// Getting a ROS param value
	var agent_priority = new ROSLIB.Param({
		ros : ros,
		name : 'speech_agent_priority'
	});
	agent_priority.get( 
		function(value) {
			var dropDownChooser = document.getElementById( 'priority_chooser');
    		if( new String(value).valueOf() == new String('human').valueOf()){
				humanPriority = true;
				showInfoPriority( 'humanPriority');
				dropDownChooser.value = "human_priority_set";
			} else if( new String(value).valueOf() == new String('robot').valueOf()){
				humanPriority = false;
				showInfoPriority( 'robotPriority');
				dropDownChooser.value = "robot_priority_set";
			} else showInfoPriority( 'errorPriority');
		}
	); 
</script>
