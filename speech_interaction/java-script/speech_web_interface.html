<!DOCTYPE html>
<!-- speech-to-text pawered by google web API -->
<!-- text-to-speech pawered by http://responsivevoice.org/-->

<meta charset="utf-8">
<!-- text-to-speech library -->
<script src='https://code.responsivevoice.org/responsivevoice.js'></script> 
<!-- ros interfacing library -->
<script type="text/javascript" src="http://static.robotwebtools.org/EventEmitter2/current/eventemitter2.min.js"></script>
<script type="text/javascript" src="http://static.robotwebtools.org/roslibjs/current/roslib.min.js"></script>

<!-- [[[[[[[[[[[[[[[[[[[[[[[[  VISUAL OBJECTS  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<title>Google Speech Recogniton and Synthesizer Demo Interface for ROS</title>
<style>
	* {
		font-family: Verdana, Arial, sans-serif;
	}
	a:link {
		color:#009933;
	}
	a:visited {
		color:#006600;
	}
	a:hover {
		color:#00cc99;
	}
	.center {
		padding: 10px;
		text-align: center;
	}
	.final {
		color: black;
		padding-right: 3px; 
	}
	.interim {
		color: gray;
	}
	.info {
		font-size: 14px;
		text-align: center;
		color: #dfdcdc;
		display: none;
	}
	.right {
		float: right;
	}
	.sidebyside {
		display: inline-block;
		width: 45%;
		min-height: 40px;
		text-align: left;
		vertical-align: top;
	}
	#headline {
		font-size: 40px;
		font-weight: 300;
	}
	#info {
		font-size: 20px;
		text-align: center;
		color: #dfdcdc;
		visibility: hidden;
	}
	#info2 {
		font-size: 20px;
		text-align: center;
		color: #dfdcdc;
	}
	#infoSpeech{
		font-size: 20px;
		text-align: center;
		color: #dfdcdc;
	}
	#info_priority{
		font-size: 14px;
		text-align: center;
		color: #dfdcdc;
	}
	#results {
		font-size: 14px;
		font-weight: bold;
		border: 1px solid #ddd;
		padding: 15px;
		text-align: left;
		min-height: 80px;
	}
	#inter_results {
		font-size: 12px;
		border: 1px solid #ddd;
		padding: 15px;
		text-align: left;
		min-height: 50px;
	}
	#resultsSpeech{ 
		font-size: 12px;
		border: 1px solid #ddd;
		padding: 15px;
		text-align: left;
		min-height: 50px;
	}
	#start_button {
		border: 0;
		background-color:transparent;
		padding: 0;
	}
	#section{
		font-size: 16px;
		font-weight: bold;
		color: #dfdcdc;
		text-align: right;
	}
	#documentation{
		font-size: 12px;
		color: #dfdcdc;
		text-align: left;
	}
</style>


<!-- [[[[[[[[[[[[[[[[[[[[[[[[   SET PAGE CONTENTS  ]]]]]]]]]]]]]]]]]]]]]]]  -->

<!-- test 
<button onclick="myFunction()">Click to simulate a "stop" sentence</button>
<script>
function myFunction() {
  // publish dummy values data on ROS
	var message = new ROSLIB.Message({
		language : "Test",
		transcript : "stop",
		confidence : 1.0
	});
	pub.publish( message);	
}
</script>
-->

<!-- title -->
<h1 class="center" id="headline"> Qualitative Miro Teleoping </h1>




<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
* {
    box-sizing: border-box;
}

/* Create two unequal columns that floats next to each other */
.column {
    float: left;
    padding: 10px;
}

.left {
  width: 65%;
}

.right {
  width: 35%;
}

/* Clear floats after the columns */
.row:after {
    content: "";
    display: table;
    clear: both;
}
</style>
</head>
<body style="background-color:#2f2f2f" text="white">

<div class="row">
  <div class="column left" style="background-color:transparent;">

<!-- sppech-to-text section -->
<hr>  
<div id="info">
	<p id="info_start">Click on the microphone icon and begin speaking.
	<p id="info_speak_now">Speak now.
	<p id="info_no_speech">No speech was detected. You may need to adjust your <a href="//support.google.com/chrome/bin/answer.py?hl=en&amp;answer=1407892"> microphone settings</a>.
	<p id="info_no_microphone" style="display:none"> No microphone was found. Ensure that a microphone is installed and that <a href="//support.google.com/chrome/bin/answer.py?hl=en&amp;answer=1407892"> microphone settings</a> are configured correctly.
	<p id="info_allow">Click the "Allow" button above to enable your microphone.
	<p id="info_denied">Permission to use microphone was denied.
	<p id="info_blocked">Permission to use microphone is blocked. To change, go to chrome://settings/content/microphone.
	<p id="info_upgrade">Web Speech API is not supported by this browser. Upgrade to <a href="//www.google.com/chrome">Chrome</a> version 25 or later.
	<p id="info_pub">command send to ROS topic /speech_to_text!<br>You can keep speaking...
	<p id="info_robot_priority">The speaker priority is given to the Robot. You cannot speeach while it is speaking.
</div>
<p class="right">
	<button id="start_button" onclick="startButton(event)">
	<img id="start_img" src="mic-resources/mic.gif" alt="Start"></button>
</p>
<p id="inter_results">
	Intermidiate recognised string from speech:<br>
	<span id="interim_span" class="interim"></span>
</p>
<div id="results">
	Final recognised string from speech:<br>
	<span id="final_span" class="final"></span>
</div>
<div class="left" id="div_language">
	<br>Select the speaking language: &nbsp
	<select id="select_language" onchange="updateCountry()"></select>
	&nbsp;&nbsp; 
	<select id="select_dialect"></select>
</div>
<br>

</div>
  <div class="column right" style="background-color:transparent;">
    <hr><div id="info2">Commands</div>
    
    
    <style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-s6z2{text-align:center}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-yw4l{vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-s6z2"><span style="font-weight:bold">Color</span></th>
    <th class="tg-s6z2"><span style="font-weight:bold">Command</span></th>
  </tr>
  <tr>
    <td class="tg-baqh"><font color="green"><b>GREEN</font></td>
    <td class="tg-baqh">ready for new commnad</td>
  </tr>
  <tr>
    <td class="tg-baqh"><font color="yellow"><b>YELLOW</font></td>
    <td class="tg-baqh">computing speech and gesture</td>
  </tr>
  <tr>
    <td class="tg-baqh"><font color="#5e90ee"><b>BLUE</font></td>
    <td class="tg-baqh">goal position found</td>
  </tr>
  <tr>
    <td class="tg-baqh"><font color="red"><b>RED</font></td>
    <td class="tg-baqh">command not understood</td>
  </tr>
  <tr>
    <td class="tg-yw4l"><font color="#cb82ea"><b>PURPLE</font></td></td>
    <td class="tg-baqh">memory reset</td>
  </tr>
  <tr>
    <td class="tg-baqh"><font color="white"><b>WHITE</font></td></td>
    <td class="tg-baqh">target reached<br></td>
  </tr>
</table>
    
    
    
  </div>
</div>

</body>



</html>


<!-- text-to-speech section 
<hr>  
<div id="section">
	Text-To-Speech.
</div>
<div id="infoSpeech">
	<p id="infoSpeech_start">Speak and listen here what the system would said to you.<br><br></p>
	<p id="infoSpeech_error">Your brosware does not support audio speaking or an synthetiser error occurs!<br><br></p>
	<p id="infoSpeech_noRobot">No robot connected<br><br></p>
	<p id="infoSpeech_speak">Robot is speaking...<br><br></p>
	<p id="info_human_priority">The speaker priority is given to the Human. The robot will stop speaking as soon as you speak.</p>
</div>
<div id="resultsSpeech">
	Final string for the Speaker:<br>
	<span id="final_return" class="final"></span>
	<p>
</div>

<hr>  
<div id="section">
	ROS state.
</div>
<div class="center" id="statusIndicator">
	<p id="connecting" style="color:#FFBF00; display:none"> <br> Connecting to ROSbridge ... </p>
    <p id="connected" style="color:#009933; display:none"> <br> Successfully connected to ROSbridge :) </p>
    <p id="error" style="color:#FF4800; display:none"> <br> !!! Error in the backend !!! </p>
    <p id="closed" style="color:#BA2D1E; display:none"> <br> ??? Connection to ROSbridge closed ??? <br> Try to run: <code>roslaunch rosbridge_server rosbridge_websocket.launch</code> </p>
</div>
<div class="left">
	<br>Select the <code style="background-color:#e1eaea">agent_priority</code>:
	<select id="priority_chooser" onchange="priorityUpdate(this.value);">
		<option value="human_priority_set" selected="selected">Human Speaker Priority</option>
		<option value="robot_priority_set">Robot Speaker Priority</option>
	</select>
    (this parameter is synchronised with ROS !!!)
    <br><br>
</div>
<div id="info_priority" class="left">
    <p id="humanPriority">The human has the interaction priority. The robot is always focusing on your last query. You can do other querings while it is providing an answer.</p>
	<p id="robotPriority">The robot has the interaction priority. You cannot speech when the rebot is providing an answer.</p>
	<p id="errorPriority">Error on setting the priority from ROS parameters, you can specify only: <code style="background-color:#e1eaea">human</code> or <code style="background-color:#e1eaea">robot</code>. Using the default value: Human-Priority</p>
</div>
-->


<!-- [[[[[[[[[[[[[[[[[[[[[[[[   JAVA SCRIPT FOR SPEECH-TO-TEXT  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<script>
	var langs =
	[['Afrikaans',			['af-ZA']],
	['Bahasa Indonesia',	['id-ID']],
	['Bahasa Melayu',		['ms-MY']],
	['Català',				['ca-ES']],
	['Čeština',				['cs-CZ']],
	['Deutsch',				['de-DE']],
	['English',				['en-AU', 'Australia'],
							['en-CA', 'Canada'],
							['en-IN', 'India'],
							['en-NZ', 'New Zealand'],
							['en-ZA', 'South Africa'],
							['en-GB', 'United Kingdom'],
							['en-US', 'United States']],
	['Español',				['es-AR', 'Argentina'],
							['es-BO', 'Bolivia'],
							['es-CL', 'Chile'],
							['es-CO', 'Colombia'],
							['es-CR', 'Costa Rica'],
							['es-EC', 'Ecuador'],
							['es-SV', 'El Salvador'],
							['es-ES', 'España'],
							['es-US', 'Estados Unidos'],
							['es-GT', 'Guatemala'],
							['es-HN', 'Honduras'],
							['es-MX', 'México'],
							['es-NI', 'Nicaragua'],
							['es-PA', 'Panamá'],
							['es-PY', 'Paraguay'],
							['es-PE', 'Perú'],
							['es-PR', 'Puerto Rico'],
							['es-DO', 'República Dominicana'],
							['es-UY', 'Uruguay'],
							['es-VE', 'Venezuela']],
	['Euskara',				['eu-ES']],
	['Français',			['fr-FR']],
	['Galego',				['gl-ES']],
	['Hrvatski',			['hr_HR']],
	['IsiZulu',				['zu-ZA']],
	['Íslenska',			['is-IS']],
	['Italiano',			['it-IT', 'Italia'],
							['it-CH', 'Svizzera']],
	['Magyar',				['hu-HU']],
	['Nederlands',			['nl-NL']],
	['Norsk bokmål',		['nb-NO']],
	['Polski',				['pl-PL']],
	['Português',			['pt-BR', 'Brasil'],
							['pt-PT', 'Portugal']],
	['Română',				['ro-RO']],
	['Slovenčina',			['sk-SK']],
	['Suomi',				['fi-FI']],
	['Svenska',				['sv-SE']],
	['Türkçe',				['tr-TR']],
	['български',			['bg-BG']],
	['Pусский',				['ru-RU']],
	['Српски',				['sr-RS']],
	['한국어',				['ko-KR']],
	['中文',					['cmn-Hans-CN', '普通话 (中国大陆)'],
							['cmn-Hans-HK', '普通话 (香港)'],
							['cmn-Hant-TW', '中文 (台灣)'],
							['yue-Hant-HK', '粵語 (香港)']],
	['日本語',				['ja-JP']],
	['Lingua latīna',		['la']]];

	var humanPriority = true; // if false means robot priority // true is the default value but it can set form ROS arguments (see ros launch)
	var humanIsSpeaking = false;
	var robotIsSpeaking = false;

	for (var i = 0; i < langs.length; i++) {
		select_language.options[i] = new Option(langs[i][0], i);
	}
	select_language.selectedIndex = 6;
	updateCountry();
	select_dialect.selectedIndex = 6;
	showInfo('info_start');
	showInfoSpeaking('infoSpeech_start');

	function updateCountry() {
		for (var i = select_dialect.options.length - 1; i >= 0; i--) {
			select_dialect.remove(i);
		}
		var list = langs[select_language.selectedIndex];
		for (var i = 1; i < list.length; i++) {
			select_dialect.options.add(new Option(list[i][1], list[i][0]));
		}
		select_dialect.style.visibility = list[1].length == 1 ? 'hidden' : 'visible';
	}

	var final_transcript = '';
	var final_confidence = 0.0;
	var recognizing = false;
	var ignore_onend;
	var start_timestamp;
	if (!('webkitSpeechRecognition' in window)) {
		upgrade();
	} else {
		start_button.style.display = 'inline-block';
		var recognition = new webkitSpeechRecognition();
		recognition.continuous = true;
		recognition.interimResults = true;

		recognition.onstart = function() {
			recognizing = true;
			showInfo('info_speak_now');
			start_img.src = 'mic-resources/mic-animate.gif';			
		};

		recognition.onerror = function(event) {
			if (event.error == 'no-speech') {
				start_img.src = 'mic-resources/mic.gif';
				showInfo('info_no_speech');
				ignore_onend = true;
			}
			if (event.error == 'audio-capture') {
				start_img.src = 'mic-resources/mic.gif';
				showInfo('info_no_microphone');
				ignore_onend = true;
			}
			if (event.error == 'not-allowed') {
				if (event.timeStamp - start_timestamp < 100) {
					showInfo('info_blocked');
				} else {
					showInfo('info_denied');
				}
				ignore_onend = true;
			}
		};

		recognition.onend = function() {
			recognizing = false;
			if (ignore_onend) {
				return;
			}
			start_img.src = 'mic-resources/mic.gif';
			if (!final_transcript) {
				showInfo('info_start');
				return;
			}
			showInfo('');
			if (window.getSelection) {
				window.getSelection().removeAllRanges();
				var range = document.createRange();
				range.selectNode(document.getElementById('final_span'));
				window.getSelection().addRange(range);
			}
		};

		recognition.onresult = function(event) {
		
		    
	        var colorComputing = new ROSLIB.Param({
		        ros : ros,
		        name : '/color_key'
	        });
			colorComputing.set(4)
		
		
			var interim_transcript = '';
			var transcript_final_log = '';
			var transcript_interim_log = '';
			var interim_confidence = 0.0;
			var final_result = true;

			var humanCanSpeack = true;
			if( robotIsSpeaking && humanIsSpeaking){
				if( ! humanPriority){
					humanCanSpeack = false;
				}
			}
			if( humanCanSpeack){
				// get transcript and confidence results (search for best condifence !! ??)
				for (var i = event.resultIndex; i < event.results.length; ++i) {
					if (event.results[i].isFinal) {
						if( event.results[i][0].confidence > final_confidence){
							final_transcript += event.results[i][0].transcript;
							final_confidence = event.results[i][0].confidence;
						}
					} else {
						if( event.results[i][0].confidence > interim_confidence){
							interim_transcript += event.results[i][0].transcript;
							interim_confidence = event.results[i][0].confidence;
						}
						final_result = false;
					}
				}
				// print the results on the console
				if ( final_result){
					transcript_final_log = '[' + final_confidence + ']\t' + final_transcript;	 
					humanIsSpeaking = false;
				} else {
					transcript_interim_log = '[' + interim_confidence + ']\t'  + interim_transcript;
					humanIsSpeaking = true;
				}  
				transcript_final_log = capitalize( transcript_final_log);   
				final_span.innerHTML = linebreak( transcript_final_log);
				interim_span.innerHTML = linebreak( transcript_interim_log);
				if ( final_result){ //(final_transcript || interim_transcript) {
					showInfo( "info_pub");
					// publish data on ROS
					var message = new ROSLIB.Message({
						language : recognition.lang,
						transcript : final_transcript,
						confidence : final_confidence
					});
					pub.publish( message);					
					// clear recognised sentence 	
					final_transcript = ''; 
					final_confidence = 0.0;
				}
			} else {
				interim_transcript = '';
				interim_confidence = 0.0;
				interim_span.innerHTML = linebreak( '');
				showInfo( 'info_robot_priority');
			}
		};
	}

	function upgrade() {
		start_button.style.visibility = 'hidden';
		showInfo('info_upgrade');
	}

	var two_line = /\n\n/g;
	var one_line = /\n/g;
	function linebreak(s) {
		return s.replace(two_line, '<p></p>').replace(one_line, '<br>');
	}

	var first_char = /\S/;
	function capitalize(s) {
		return s.replace(first_char, function(m) { return m.toUpperCase(); });
	}


	function startButton(event) {
		if (recognizing) {
			recognition.stop();
			return;
		}
		final_transcript = '';
		//recognition.lang = select_dialect.value;
		recognition.start();
		ignore_onend = false;
		final_span.innerHTML = '';
		interim_span.innerHTML = '';
		start_img.src = 'mic-resources/mic-slash.gif';
		showInfo('info_allow');
		start_timestamp = event.timeStamp;
	}

	function showInfo(s) {
		if (s) {
			for (var child = info.firstChild; child; child = child.nextSibling) {
				if (child.style) {
					child.style.display = child.id == s ? 'inline' : 'none';
				}
			}
			info.style.visibility = 'visible';
		} else {
			info.style.visibility = 'hidden';
		}
	}

	function showInfoSpeaking(s) {
		if (s) {
			for (var child = infoSpeech.firstChild; child; child = child.nextSibling) {
				if (child.style) {
					child.style.display = child.id == s ? 'inline' : 'none';
				}
			}
			info.style.visibility = 'visible';
		} else {
			info.style.visibility = 'hidden';
		}
	}

	function showInfoPriority(s) {
		if (s) {
			for (var child = info_priority.firstChild; child; child = child.nextSibling) {
				if (child.style) {
					child.style.display = child.id == s ? 'inline' : 'none';
				}
			}
			info.style.visibility = 'visible';
		} else {
			info.style.visibility = 'hidden';
		}
	}

	function priorityUpdate(s) {
		if ( s == 'human_priority_set'){
			humanPriority = true;
			showInfoPriority( 'humanPriority');
		}else{
			humanPriority = false;
			showInfoPriority( 'robotPriority');
		}        
		// Setting a param value to ROS
		agent_priority.set( humanPriority);
	}
</script>



<!-- [[[[[[[[[[[[[[[[[[[[[[[[  JAVA SCRIPT FOR ROS_BRIDGE & TEXT-TO-SPEECh  ]]]]]]]]]]]]]]]]]]]]]]]  -->
<script>
	// Connecting to ROS
	var ros = new ROSLIB.Ros();

	// manage states and errors
	// If there is an error on the backend, an 'error' emit will be emitted.
	ros.on('error', function(error) {
		showInfoSpeaking('infoSpeech_noRobot'); 
		document.getElementById('connecting').style.display = 'none';
		document.getElementById('connected').style.display = 'none';
		document.getElementById('closed').style.display = 'none';
		document.getElementById('error').style.display = 'inline';
	});
	// Find out exactly when we made a connection.
	ros.on('connection', function() {
		console.log('Connection made!');
		document.getElementById('connecting').style.display = 'none';
		document.getElementById('error').style.display = 'none';
		document.getElementById('closed').style.display = 'none';
		document.getElementById('connected').style.display = 'inline';
	});
	ros.on('close', function() {
		console.log('Connection closed.');
		document.getElementById('connecting').style.display = 'none';
		document.getElementById('connected').style.display = 'none';
		document.getElementById('closed').style.display = 'inline';
	});

	// Create a connection to the rosbridge WebSocket server.
	ros.connect('ws://130.251.13.71:9090');


	// create a publisher 
	var pub = new ROSLIB.Topic({
		ros : ros,
		name : '/speech_to_text',
		messageType : 'speech_interaction/Speech2text'
	});

	//Subscribing to a Topic
	var listener = new ROSLIB.Topic({
		ros : ros,
		name : '/text_to_speech',
		messageType : 'speech_interaction/Text2speech'
	});

	// Then we add a callback to be called every time a message is published on this topic.
	listener.subscribe( function(message) {
		// manage speaker priority
		var robotCanSpeack = true;
		if( robotIsSpeaking && humanIsSpeaking){
			if( humanPriority){
				robotCanSpeack = false;
			}
		}
		if( robotCanSpeack){
			if(responsiveVoice.voiceSupport()) {
				// visualise speeck
				final_return.innerHTML = linebreak( message.text + '\n[language: ' + message.language + '] [ volume: ' + message.volume + '] [ pitch: ' + message.pitch + '] [ rate: ' + message.rate + ']');
				// speech
				showInfoSpeaking('infoSpeech_speak');
				responsiveVoice.speak( message.text, message.language, callbacks, message.volume, message.pitch, message.rate);	
			} else {
				showInfoSpeaking('infoSpeech_error'); 
			}
		} else {
			showInfoSpeaking( 'info_human_priority');
		}
	});

	// functions to manage text to speech 
	var callbacks = {
		onstart: voiceStartCallback,
		onend: voiceEndCallback,
		onerror: voiceErrorCallback, 
		onpause: voicePauseCallback
		// onresume
	}
	function voiceStartCallback() {
		robotIsSpeaking = true;
	}
	function voiceEndCallback() {
		showInfoSpeaking('infoSpeech_start');
		if( !humanPriority)
			showInfo( 'info_speak_now');
		robotIsSpeaking = false;
	}
	function voiceErrorCallback() {
		showInfoSpeaking('infoSpeech_error'); 
		robotIsSpeaking = false;
	}
	function voicePauseCallback() {
		showInfoSpeaking( 'info_human_priority');
		robotIsSpeaking = false;
	}

  	// Getting a ROS param value
	var agent_priority = new ROSLIB.Param({
		ros : ros,
		name : 'speech_agent_priority'
	});
	agent_priority.get( 
		function(value) {
			var dropDownChooser = document.getElementById( 'priority_chooser');
    		if( new String(value).valueOf() == new String('human').valueOf()){
				humanPriority = true;
				showInfoPriority( 'humanPriority');
				dropDownChooser.value = "human_priority_set";
			} else if( new String(value).valueOf() == new String('robot').valueOf()){
				humanPriority = false;
				showInfoPriority( 'robotPriority');
				dropDownChooser.value = "robot_priority_set";
			} else showInfoPriority( 'errorPriority');
		}
	); 
</script>
